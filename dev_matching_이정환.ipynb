{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdOq73py6pMv"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qJrRK_yZ-dw",
    "outputId": "9d49794a-47f1-4ac8-fbe2-6cb92c79f4ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 23 07:08:02 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    22W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YIsGdKo6u04"
   },
   "source": [
    "# Install libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlMR1-aismie",
    "outputId": "045d830c-46ee-4142-d877-140bfc9ce6e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.4.9)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.9.1+cu101)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.8.1+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.1.2.30)\n",
      "Requirement already satisfied: imgaug<0.2.7,>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.2.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.16.2)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.1.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.2)\n",
      "Collecting git+https://github.com/ildoonet/pytorch-randaugment\n",
      "  Cloning https://github.com/ildoonet/pytorch-randaugment to /tmp/pip-req-build-r92r8990\n",
      "  Running command git clone -q https://github.com/ildoonet/pytorch-randaugment /tmp/pip-req-build-r92r8990\n",
      "Requirement already satisfied (use --upgrade to upgrade): RandAugment==0.1 from git+https://github.com/ildoonet/pytorch-randaugment in /usr/local/lib/python3.7/dist-packages\n",
      "Building wheels for collected packages: RandAugment\n",
      "  Building wheel for RandAugment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for RandAugment: filename=RandAugment-0.1-cp37-none-any.whl size=24212 sha256=bd8f946ac34b47c693930cb5ec9ccc08cf89d6bf5558cc5a4125e97930f2181b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-j0h2gqo5/wheels/0d/0e/e9/f8b70c1e233491338d524d867a7e959d10bb14a16bd5379b09\n",
      "Successfully built RandAugment\n",
      "Collecting git+https://github.com/ildoonet/pytorch-randaugment\n",
      "  Cloning https://github.com/ildoonet/pytorch-randaugment to /tmp/pip-req-build-bgxag6mm\n",
      "  Running command git clone -q https://github.com/ildoonet/pytorch-randaugment /tmp/pip-req-build-bgxag6mm\n",
      "Requirement already satisfied (use --upgrade to upgrade): RandAugment==0.1 from git+https://github.com/ildoonet/pytorch-randaugment in /usr/local/lib/python3.7/dist-packages\n",
      "Building wheels for collected packages: RandAugment\n",
      "  Building wheel for RandAugment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for RandAugment: filename=RandAugment-0.1-cp37-none-any.whl size=24212 sha256=aee0e8ffcfa0d1970288237921b9cba32c470aa71a5c5c2b1599193da2f15778\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3gwc443m/wheels/0d/0e/e9/f8b70c1e233491338d524d867a7e959d10bb14a16bd5379b09\n",
      "Successfully built RandAugment\n"
     ]
    }
   ],
   "source": [
    "!pip install timm\n",
    "!pip install transformers\n",
    "!pip install albumentations\n",
    "!pip install git+https://github.com/ildoonet/pytorch-randaugment\n",
    "!pip install git+https://github.com/ildoonet/pytorch-randaugment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkMqm5_8Nc1h"
   },
   "source": [
    "# Extract Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-CLzBaSB_IK"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/drive/MyDrive/dev/test.zip -d /content/drive/MyDrive/dev/test\n",
    "# !unzip /content/drive/MyDrive/dev/train.zip -d /content/drive/MyDrive/dev/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2uML4_X7KXf"
   },
   "source": [
    "# Image Augmentation(HorizontalFlip)\n",
    "#### - crop, rotation, randaugment 등의 Augmentation은 성능 향상이 없어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nzyXHjyiNb0Z"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from RandAugment import RandAugment\n",
    "\n",
    "# transforms.RandomHorizontalFlip(1),\n",
    "# transforms.CenterCrop((450,225)),\n",
    "# transforms.RandomRotation(5),\n",
    "# transforms.RandomHorizontalFlip(0),\n",
    "# transforms.RandomHorizontalFlip(0),\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "                                    transforms.Resize((224, 224)),\n",
    "                                    #transforms.RandomResizedCrop(190),\n",
    "                                    transforms.RandomHorizontalFlip(0.5),\n",
    "                                    #RandAugment(1,5),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "                                    transforms.Resize((224, 224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSmJXadt7gpW"
   },
   "source": [
    "# Data Loader(train, val, test)를 위한 Custom Dataset Class 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ixMo4l-U7cug"
   },
   "outputs": [],
   "source": [
    "def get_label(image_path):    #image 경로로부터 label을 추출\n",
    "    if \"dog\" in image_path:\n",
    "        return 0\n",
    "    elif \"elephant\" in image_path:\n",
    "        return 1\n",
    "    elif \"giraffe\" in image_path:\n",
    "        return 2\n",
    "    elif \"guitar\" in image_path:\n",
    "        return 3\n",
    "    elif \"horse\" in image_path:\n",
    "        return 4\n",
    "    elif \"house\" in image_path:\n",
    "        return 5\n",
    "    elif \"person\" in image_path:\n",
    "        return 6\n",
    "    else:\n",
    "        print(f\"error!!! : {image_path}\")\n",
    "        return -1\n",
    "\n",
    "class Dataset_Train(Dataset):    #Train Dataset 생성을 위한 Class. image와 label을 return함\n",
    "    def __init__(self, data_list, transform):\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.data_list[idx]\n",
    "        label = get_label(image_path)\n",
    "        img = Image.open(image_path)\n",
    "        img = self.transform(img)\n",
    "        return img, label\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "class Dataset_Test(Dataset):    #Test Dataset 생성을 위한 Class. image만 transform 하여 return\n",
    "    def __init__(self, data_list, transform):\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.data_list[idx]\n",
    "        img = Image.open(image_path)\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYsnqaqq7vaH"
   },
   "source": [
    "# Base model, Hyperparameter 정의 및 시드 고정\n",
    "#### - 앙상블에 사용한 model : hrnet_w40(stratified k-fold, train all datasets), hrnet_w64(train all datasets)\n",
    "#### - 시도하였으나 성능이 나빠 사용하지 않은 모델 : efficientnet-b0, b3, b6\n",
    "#### Hyperparameters\n",
    " - batch_size : 64\n",
    " - lr : 0.0001\n",
    " - momentum : 0.9\n",
    " - weight_decay :0.005\n",
    " - restarts(scheduler) : 5\n",
    " - num_epochs : 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uDOWjeYoz8-P"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "random_seed = 11\n",
    "num_classes = 7 \n",
    "base_model = 'hrnet_w40'\n",
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.005\n",
    "restarts = 5\n",
    "num_epochs = 70\n",
    "model_name = 'hrnet_w40'\n",
    "\n",
    "torch.backends.cudnn.deterministic = True    #GPU 메모리 관리를 위해 작성\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDobU6LZ9PbL"
   },
   "source": [
    "# 5 fold Division\n",
    "#### - Startified k-fold를 위해 전체 데이터셋의 class 비율에 맞춰 fold를 5개로 나누어줌. 또한 전체 데이터셋도 학습한 모델을 가지기 위해 전체 데이터셋도 생성\n",
    "#### - 클래스 데이터셋을 5등분하여 5등분점을 기준으로 각 fold(0~4)에 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4kEDziA9XWh",
    "outputId": "1cdea911-cc98-4a1d-e482-35e93397e002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>,\n",
      "            {0: 329,\n",
      "             1: 205,\n",
      "             2: 235,\n",
      "             3: 134,\n",
      "             4: 151,\n",
      "             5: 245,\n",
      "             6: 399})\n",
      "0 fold train data : 1361\n",
      "0 fold val data : 337\n",
      "1 fold train data : 1358\n",
      "1 fold val data : 340\n",
      "2 fold train data : 1358\n",
      "2 fold val data : 340\n",
      "3 fold train data : 1358\n",
      "3 fold val data : 340\n",
      "4 fold train data : 1357\n",
      "4 fold val data : 341\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "all_train_images = sorted(glob('/content/drive/MyDrive/dev/train/train/*/*'))\n",
    "class_images = []\n",
    "fold_images = [[] for _ in range(5)]\n",
    "label_to_class = {0:'dog',1:'elephant',2:'giraffe',3:'guitar',4:'horse',5:'house',6:'person'}\n",
    "\n",
    "for i in range(7):\n",
    "    temp_arr = []\n",
    "    class_image = sorted(glob(f'/content/drive/MyDrive/dev/train/train/{label_to_class[i]}/*'))\n",
    "    class_images.append(class_image)\n",
    "\n",
    "train_images = []\n",
    "test_images = sorted(glob('/content/drive/MyDrive/dev/test/test/*/*'))\n",
    "class_dict = defaultdict(int)\n",
    "\n",
    "for elem in all_train_images:\n",
    "    label = get_label(elem)\n",
    "    class_dict[label]+=1\n",
    "\n",
    "pprint(class_dict)\n",
    "\n",
    "folds = 5\n",
    "\n",
    "for k in class_dict.keys():    #각 클래스 데이터셋을 5등분하여 등분점의 index를 잡고, 해당 index를 기준으로 데이터를 나누어 fold마다 삽입\n",
    "    fold_idx = [class_dict[k]//5,class_dict[k]*2//5,class_dict[k]*3//5,class_dict[k]*4//5,class_dict[k]]\n",
    "    start = 0\n",
    "    for i,elem in enumerate(fold_idx):\n",
    "        end = fold_idx[i]\n",
    "        fold_images[i].extend(class_images[k][start:end])\n",
    "        start = end\n",
    "\n",
    "train_folds = [[] for _ in range(5)]\n",
    "val_folds = [[] for _ in range(5)]\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i==j:\n",
    "            continue\n",
    "        train_folds[i].extend(fold_images[j])\n",
    "    print(f'{i} fold train data : {len(train_folds[i])}')\n",
    "    val_folds[i] = fold_images[i]\n",
    "    print(f'{i} fold val data : {len(val_folds[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2g8bDTWf-a0r"
   },
   "source": [
    "# Initialize Loader\n",
    "#### Dataset으로부터 loader를 만들어 줌(k-fold loader, all dataset loader, test loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0H_YJa1f-XM6"
   },
   "outputs": [],
   "source": [
    "train_datasets = [[] for _ in range(5)]\n",
    "val_datasets = [[] for _ in range(5)]\n",
    "train_loaders = [[] for _ in range(5)]\n",
    "val_loaders = [[] for _ in range(5)]\n",
    "\n",
    "for i in range(5):\n",
    "    train_datasets[i] = Dataset_Train(train_folds[i],train_transform)\n",
    "    val_datasets[i] = Dataset_Train(val_folds[i],test_transform)\n",
    "    train_loaders[i] = DataLoader(train_datasets[i],batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "    val_loaders[i] = DataLoader(val_datasets[i],shuffle=False)\n",
    "\n",
    "dataset_train_all = Dataset_Train(all_train_images,train_transform)\n",
    "dataset_test = Dataset_Test(test_images,test_transform)\n",
    "\n",
    "all_train_loader = DataLoader(dataset_train_all,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "test_loader = DataLoader(dataset_test,shuffle=False)\n",
    "\n",
    "for elem in all_train_images:    #label이 잘못되었는지 check\n",
    "    if get_label(elem) not in [0,1,2,3,4,5,6]:\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTckrrg7-9qe"
   },
   "source": [
    "# Create Model, Optimizer, Scheduler\n",
    "#### - loss : CE loss 사용. focal loss는 성능 향상이 없어 제거\n",
    "#### - optimizer : SGD (Adam 보다 실험 결과 성능이 좋아 사용)\n",
    "#### - scheduler : CosineAnnealingWarmRestarts\n",
    "#### - model : timm(torch image models) open source libarary를 이용해 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1R9behxlxsx4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import timm\n",
    "m = timm.create_model(base_model, pretrained=True, num_classes = num_classes)\n",
    "\n",
    "optimizer = optim.SGD(m.parameters(),lr=lr,momentum=momentum,weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,restarts)\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRFO40hn_1ZJ"
   },
   "source": [
    "# Train\n",
    "#### - train 은 epoch 당 train->validation 순서로 이루어지며, validation accuracy가 최고를 갱신하면 best 모델로 저장하며 학습\n",
    "#### - 해당 방식으로 0~4fold 및 데이터셋 전체를 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zslrmRY_Tune",
    "outputId": "5ca24ae1-d8b1-4901-da24-11bb8bdee3af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/70 epochs\n",
      "-----------\n",
      "train loss : 1.8516\n",
      "train acc : 0.23803\n",
      "eval loss : 1.81326\n",
      "eval acc : 0.23754\n",
      "best model saved : 'hrnet_w40_4fold_best.pt\n",
      "epoch train time : 0min 37sec\n",
      "2/70 epochs\n",
      "-----------\n",
      "train loss : 1.75538\n",
      "train acc : 0.27119\n",
      "eval loss : 1.73616\n",
      "eval acc : 0.28152\n",
      "best model saved : 'hrnet_w40_4fold_best.pt\n",
      "epoch train time : 0min 37sec\n",
      "3/70 epochs\n",
      "-----------\n",
      "train loss : 1.67886\n",
      "train acc : 0.35225\n",
      "eval loss : 1.67354\n",
      "eval acc : 0.3695\n",
      "best model saved : 'hrnet_w40_4fold_best.pt\n",
      "epoch train time : 0min 37sec\n",
      "4/70 epochs\n",
      "-----------\n",
      "train loss : 1.6088\n",
      "train acc : 0.45615\n",
      "eval loss : 1.61296\n",
      "eval acc : 0.44282\n",
      "best model saved : 'hrnet_w40_4fold_best.pt\n",
      "epoch train time : 0min 37sec\n",
      "5/70 epochs\n",
      "-----------\n",
      "train loss : 1.53918\n",
      "train acc : 0.53279\n",
      "eval loss : 1.55204\n",
      "eval acc : 0.5044\n",
      "best model saved : 'hrnet_w40_4fold_best.pt\n",
      "epoch train time : 0min 37sec\n",
      "6/70 epochs\n",
      "-----------\n",
      "train loss : 1.46454\n",
      "train acc : 0.59985\n",
      "eval loss : 1.49157\n",
      "eval acc : 0.55425\n",
      "best model saved : 'hrnet_w40_4fold_best.pt\n",
      "epoch train time : 0min 37sec\n",
      "7/70 epochs\n",
      "-----------\n",
      "train loss : 1.39199\n",
      "train acc : 0.6448\n",
      "eval loss : 1.42958\n",
      "eval acc : 0.61877\n",
      "best model saved : 'hrnet_w40_4fold_best.pt\n",
      "epoch train time : 0min 37sec\n",
      "8/70 epochs\n",
      "-----------\n",
      "train loss : 1.31846\n",
      "train acc : 0.69492\n",
      "eval loss : 1.36936\n",
      "eval acc : 0.64516\n",
      "best model saved : 'hrnet_w40_4fold_best.pt\n",
      "epoch train time : 0min 37sec\n",
      "9/70 epochs\n",
      "-----------\n",
      "train loss : 1.24829\n",
      "train acc : 0.72808\n",
      "eval loss : 1.30748\n",
      "eval acc : 0.68328\n",
      "best model saved : 'hrnet_w40_4fold_best.pt\n",
      "epoch train time : 0min 37sec\n",
      "10/70 epochs\n",
      "-----------\n",
      "train loss : 1.18002\n",
      "train acc : 0.75682\n",
      "eval loss : 1.24323\n",
      "eval acc : 0.71261\n",
      "best model saved : 'hrnet_w40_4fold_best.pt\n",
      "epoch train time : 0min 37sec\n",
      "11/70 epochs\n",
      "-----------\n",
      "train loss : 1.11275\n",
      "train acc : 0.78335\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "device = torch.device('cuda')\n",
    "model_save_dir = \"/content/drive/MyDrive/dev/models\"\n",
    "def train(model,model_name,num_epochs,fold,criterion,optimizer,scheduler):\n",
    "    model.to(device)\n",
    "    train_loader = train_loaders[fold]\n",
    "    val_loader = val_loaders[fold]\n",
    "    best_eval_acc = 0.0\n",
    "    best_eval_loss = 1.0\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print(f'{epoch+1}/{num_epochs} epochs')\n",
    "        print('-----------')\n",
    "        train_loss, train_corrects, train_labels = 0,0,0\n",
    "        eval_loss, eval_corrects, eval_labels = 0,0,0\n",
    "\n",
    "        #train\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:   \n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            train_corrects += torch.sum(preds==labels.data)\n",
    "            train_labels += len(labels)\n",
    "\n",
    "        train_avg_loss = float(train_loss/train_labels)\n",
    "        train_acc = float(train_corrects.double()/train_labels)\n",
    "\n",
    "        print(f\"train loss : {round(train_avg_loss,5)}\")\n",
    "        print(f\"train acc : {round(train_acc,5)}\")\n",
    "\n",
    "        #val\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for inputs, labels in val_loader:   \n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = torch.tensor(0.0).to(device)\n",
    "                \n",
    "\n",
    "                _, preds = torch.max(outputs,1)            \n",
    "                loss = criterion(outputs,labels)\n",
    "                eval_loss += loss.item() * inputs.size(0)\n",
    "                eval_corrects += torch.sum(preds==labels.data)\n",
    "                eval_labels += len(labels)\n",
    "\n",
    "                 \n",
    "            eval_avg_loss = float(eval_loss/eval_labels)\n",
    "            eval_acc = float(eval_corrects.double()/eval_labels)\n",
    "            \n",
    "            print(f\"eval loss : {round(eval_avg_loss,5)}\")\n",
    "            print(f\"eval acc : {round(eval_acc,5)}\")\n",
    "\n",
    "            if eval_acc>=best_eval_acc:    #validation acc 기준으로 모델 저장\n",
    "                best_eval_acc = eval_acc\n",
    "                torch.save(model.state_dict(),f'{model_save_dir}/{model_name}_{fold}fold_best.pth')\n",
    "                print(f\"best model saved : '{model_name}_{fold}fold_best.pt\")\n",
    "        time_spent = time.time() - start\n",
    "        print(f\"epoch train time : {round(time_spent//60)}min {round(time_spent%60)}sec\")\n",
    "    del loss\n",
    "    del labels\n",
    "    del inputs\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.save(model.state_dict(),f'{model_save_dir}/{model_name}_ep_{epoch}.pth')\n",
    "\n",
    "fold = 4\n",
    "train(model=m, model_name=model_name, num_epochs=num_epochs, fold = fold, criterion=loss, optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjrhqNXHAv26"
   },
   "source": [
    "# Inference\n",
    "#### - 해당 fold의 best checkpoint를 불러와 inference\n",
    "#### - soft vote ensemblem을 위해 argmax 하기 전의 logit 값을 pickle로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0pOr_ZyG8Jn",
    "outputId": "d7f41ae9-d6ca-4233-88ed-b84fd89791cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [00:14<00:00, 23.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "load_epoch = num_epochs\n",
    "\n",
    "cp_path = f'{model_save_dir}/{model_name}_{fold}fold_best.pth'\n",
    "submission = pd.read_csv('/content/drive/MyDrive/dev/test_answer_sample_.csv')\n",
    "\n",
    "all_predictions = []\n",
    "all_predictions_logit = []\n",
    "m.load_state_dict(torch.load(cp_path))\n",
    "m.to(device)\n",
    "m.eval()\n",
    "\n",
    "for images in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = m(images)\n",
    "        all_predictions_logit.append(pred)\n",
    "        pred = pred.argmax()\n",
    "        all_predictions.append(pred)\n",
    "        \n",
    "# save\n",
    "with open(f'{model_save_dir}/{model_name}_fold{fold}.pickle', 'wb') as f:\n",
    "    pickle.dump(all_predictions_logit, f, pickle.HIGHEST_PROTOCOL)\n",
    "del m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmedvp75BHUT"
   },
   "source": [
    "# Export data to CSV\n",
    "#### - 단일 모델 CSV 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32Jv6Y3E0tlS"
   },
   "outputs": [],
   "source": [
    "submission['answer value'] = list(map(int,all_predictions))\n",
    "submission.columns\n",
    "submission = submission.drop(['Unnamed: 0'],axis=1)\n",
    "submission.to_csv(f'/content/drive/MyDrive/dev/submission/{model_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "iIpLzU1V1YQ0",
    "outputId": "8aaa8802-9a48-4c08-af4b-58a6befc3205"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     answer value\n",
       "0               1\n",
       "1               3\n",
       "2               1\n",
       "3               4\n",
       "4               3\n",
       "..            ...\n",
       "345             6\n",
       "346             3\n",
       "347             3\n",
       "348             5\n",
       "349             2\n",
       "\n",
       "[350 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMCQ1fvE43cB"
   },
   "source": [
    "# Ensemble\n",
    "\n",
    "#### - 이전에 저장했던 logit값을 불러와 weghted sum -> argmax를 구하는 형태로 soft voting\n",
    "#### - soft vote 하되, Public Leaderboard 점수에 따라 weight를 차등 부여하여 Ensemble함\n",
    "#### - 다양한 조합으로 앙상블 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "j_o9CBgRzpEA"
   },
   "outputs": [],
   "source": [
    "ensembles = ['/content/drive/MyDrive/dev/models/hrnet_w40_hf_64_50ep_ep_50.pickle',\n",
    "             '/content/drive/MyDrive/dev/models/hrnet_w40_hf_ep_70.pickle',\n",
    "             '/content/drive/MyDrive/dev/models/hrnet_w40_ep_70_2.pickle',\n",
    "             '/content/drive/MyDrive/dev/models/hrnet_w64_hf_ep_50.pickle',\n",
    "             '/content/drive/MyDrive/dev/models/hrnet_w40_fold0.pickle',\n",
    "             '/content/drive/MyDrive/dev/models/hrnet_w40_fold1.pickle',\n",
    "             '/content/drive/MyDrive/dev/models/hrnet_w40_fold2.pickle',\n",
    "             '/content/drive/MyDrive/dev/models/hrnet_w40_fold3.pickle',\n",
    "             '/content/drive/MyDrive/dev/models/hrnet_w40_fold4.pickle',\n",
    "             ]\n",
    "             \n",
    "weight = [1,4,1,1,1,1,1,1,1]\n",
    "pred_final = []\n",
    "all_data = []\n",
    "for i,elem in enumerate(ensembles):\n",
    "    with open(elem, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        all_data.append(data)\n",
    "\n",
    "for i in range(len(data)):    #350 \n",
    "    temp = all_data[0][i]*weight[0]\n",
    "    for j in range(1,len(ensembles)):\n",
    "        temp+=all_data[j][i]*weight[j]\n",
    "    pred_final.append(temp.argmax())\n",
    "\n",
    "submission = pd.read_csv('/content/drive/MyDrive/dev/test_answer_sample_.csv')\n",
    "submission['answer value'] = list(map(int,pred_final))\n",
    "submission = submission.drop(['Unnamed: 0'],axis=1)\n",
    "submission.to_csv(f'/content/drive/MyDrive/dev/submission/submission_final.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ic_base.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
